{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison Lab\n",
    "\n",
    "In this lab we will compare the performance of all the models we have learned about so far, using the car evaluation dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare the data\n",
    "\n",
    "The [car evaluation dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/car/) is in the assets/datasets folder. By now you should be very familiar with this dataset.\n",
    "\n",
    "1. Load the data into a pandas dataframe\n",
    "- Encode the categorical features properly: define a map that preserves the scale (assigning smaller numbers to words indicating smaller quantities)\n",
    "- Separate features from target into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-28T15:25:47.354446",
     "start_time": "2016-10-28T15:25:47.347167"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-28T15:30:54.006236",
     "start_time": "2016-10-28T15:30:54.000994"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree, ensemble, preprocessing, model_selection, metrics, neighbors, linear_model, svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-28T15:25:47.451286",
     "start_time": "2016-10-28T15:25:47.415315"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../assets/datasets/car.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-28T15:25:47.489815",
     "start_time": "2016-10-28T15:25:47.455682"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>acceptability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety acceptability\n",
       "0  vhigh  vhigh     2       2    small    low         unacc\n",
       "1  vhigh  vhigh     2       2    small    med         unacc\n",
       "2  vhigh  vhigh     2       2    small   high         unacc\n",
       "3  vhigh  vhigh     2       2      med    low         unacc\n",
       "4  vhigh  vhigh     2       2      med    med         unacc"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-28T15:25:47.501164",
     "start_time": "2016-10-28T15:25:47.494426"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1728, 7)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-28T15:25:47.520015",
     "start_time": "2016-10-28T15:25:47.512770"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-28T15:25:47.529693",
     "start_time": "2016-10-28T15:25:47.523279"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = le.fit_transform(df['acceptability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-28T15:25:47.555933",
     "start_time": "2016-10-28T15:25:47.532778"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.get_dummies(df.iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Useful preparation\n",
    "\n",
    "Since we will compare several models, let's write a couple of helper functions.\n",
    "\n",
    "1. Separate X and y between a train and test set, using 30% test set, random state = 42\n",
    "    - make sure that the data is shuffled and stratified\n",
    "2. Define a function called `evaluate_model`, that trains the model on the train set, tests it on the test, calculates:\n",
    "    - accuracy score\n",
    "    - confusion matrix\n",
    "    - classification report\n",
    "3. Initialize a global dictionary to store the various models for later retrieval\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-28T13:32:41.335148",
     "start_time": "2016-10-28T13:32:41.326058"
    },
    "collapsed": false
   },
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, stratify=y, random_state=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-28T15:25:47.564956",
     "start_time": "2016-10-28T15:25:47.559963"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skf = model_selection.StratifiedKFold(shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-28T15:25:47.586577",
     "start_time": "2016-10-28T15:25:47.569397"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for train, test in skf.split(X,y):\n",
    "    X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "    y_train, y_test = y[train], y[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-28T15:25:47.603173",
     "start_time": "2016-10-28T15:25:47.590684"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = tree.DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-28T15:25:47.615853",
     "start_time": "2016-10-28T15:25:47.606855"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['acc', 'good', 'unacc', 'vgood'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-28T15:25:47.633651",
     "start_time": "2016-10-28T15:25:47.619133"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, name):\n",
    "    mod = model.fit(X_train, y_train)\n",
    "    y_pred = mod.predict(X_test)\n",
    "    print '{} accuracy score: {}'.format(name, mod.score(X_test, y_test))\n",
    "    \n",
    "    conmat = metrics.confusion_matrix(y_test, y_pred)\n",
    "    conmat = pd.DataFrame(conmat, columns = le.classes_, index=le.classes_)\n",
    "    print\n",
    "    print conmat\n",
    "    \n",
    "    class_rep = metrics.classification_report(y_test, y_pred)\n",
    "    print\n",
    "    print class_rep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.a KNN\n",
    "\n",
    "Let's start with `KNeighborsClassifier`.\n",
    "\n",
    "1. Initialize a KNN model\n",
    "- Evaluate it's performance with the function you previously defined\n",
    "- Find the optimal value of K using grid search\n",
    "    - Be careful on how you perform the cross validation in the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-28T15:25:47.705061",
     "start_time": "2016-10-28T15:25:47.636921"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN accuracy score: 0.857391304348\n",
      "\n",
      "       acc  good  unacc  vgood\n",
      "acc     82     1     45      0\n",
      "good    15     6      2      0\n",
      "unacc    3     0    400      0\n",
      "vgood   12     1      3      5\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.64      0.68       128\n",
      "          1       0.75      0.26      0.39        23\n",
      "          2       0.89      0.99      0.94       403\n",
      "          3       1.00      0.24      0.38        21\n",
      "\n",
      "avg / total       0.85      0.86      0.84       575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(neighbors.KNeighborsClassifier(), 'kNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.b Bagging + KNN\n",
    "\n",
    "Now that we have found the optimal K, let's wrap `KNeighborsClassifier` in a BaggingClassifier and see if the score improves.\n",
    "\n",
    "1. Wrap the KNN model in a Bagging Classifier\n",
    "- Evaluate performance\n",
    "- Do a grid search only on the bagging classifier params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-28T15:25:48.311608",
     "start_time": "2016-10-28T15:25:47.708713"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagged kNN accuracy score: 0.918260869565\n",
      "\n",
      "       acc  good  unacc  vgood\n",
      "acc    101     4     23      0\n",
      "good     5    14      2      2\n",
      "unacc    8     0    395      0\n",
      "vgood    3     0      0     18\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.79      0.82       128\n",
      "          1       0.78      0.61      0.68        23\n",
      "          2       0.94      0.98      0.96       403\n",
      "          3       0.90      0.86      0.88        21\n",
      "\n",
      "avg / total       0.92      0.92      0.92       575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(ensemble.BaggingClassifier(neighbors.KNeighborsClassifier()), 'Bagged kNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-28T15:28:29.708628",
     "start_time": "2016-10-28T15:26:07.790164"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=BaggingClassifier(base_estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': array([1, 2, 3, 4, 5, 6, 7, 8, 9]), 'max_samples': array([ 0.5,  0.6,  0.7,  0.8,  0.9]), 'max_features': array([ 0.5,  0.6,  0.7,  0.8,  0.9])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = model_selection.GridSearchCV(ensemble.BaggingClassifier(neighbors.KNeighborsClassifier()),\n",
    "                                 {'n_estimators': np.arange(1,10,1), \n",
    "                                  'max_samples': np.arange(0.5,1.0,0.1), \n",
    "                                  'max_features': np.arange(0.5,1.0,0.1)},\n",
    "                                 cv=5)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-28T15:28:29.807002",
     "start_time": "2016-10-28T15:28:29.711739"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearched Bagged kNN accuracy score: 0.779130434783\n",
      "\n",
      "       acc  good  unacc  vgood\n",
      "acc     51     0     77      0\n",
      "good     8     3     12      0\n",
      "unacc   15     1    384      3\n",
      "vgood    4     0      7     10\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.40      0.50       128\n",
      "          1       0.75      0.13      0.22        23\n",
      "          2       0.80      0.95      0.87       403\n",
      "          3       0.77      0.48      0.59        21\n",
      "\n",
      "avg / total       0.76      0.78      0.75       575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(gs.best_estimator_, 'GridSearched Bagged kNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Logistic Regression\n",
    "\n",
    "Let's see if logistic regression performs better\n",
    "\n",
    "1. Initialize LR and test on Train/Test set\n",
    "- Find optimal params with Grid Search\n",
    "- See if Bagging improves the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-28T15:28:30.408892",
     "start_time": "2016-10-28T15:28:29.810176"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy score: 0.867826086957\n",
      "\n",
      "       acc  good  unacc  vgood\n",
      "acc     96     6     26      0\n",
      "good    15     7      0      1\n",
      "unacc   13     1    389      0\n",
      "vgood   14     0      0      7\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.75      0.72       128\n",
      "          1       0.50      0.30      0.38        23\n",
      "          2       0.94      0.97      0.95       403\n",
      "          3       0.88      0.33      0.48        21\n",
      "\n",
      "avg / total       0.86      0.87      0.86       575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(linear_model.LogisticRegression(), 'Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-28T15:28:31.271420",
     "start_time": "2016-10-28T15:28:30.412636"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 0.2, 0.3, 0.5, 1.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs2 = model_selection.GridSearchCV(linear_model.LogisticRegression(),\n",
    "                                   {'C': [0.001,0.01,0.1,0.2,0.3,0.5,1.0],\n",
    "                                   'penalty': ['l1', 'l2']},\n",
    "                                   cv=5)\n",
    "gs2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-28T15:28:31.317353",
     "start_time": "2016-10-28T15:28:31.275655"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearched Logistic Regression accuracy score: 0.838260869565\n",
      "\n",
      "       acc  good  unacc  vgood\n",
      "acc     85     0     43      0\n",
      "good    23     0      0      0\n",
      "unacc    6     0    397      0\n",
      "vgood   21     0      0      0\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.66      0.65       128\n",
      "          1       0.00      0.00      0.00        23\n",
      "          2       0.90      0.99      0.94       403\n",
      "          3       0.00      0.00      0.00        21\n",
      "\n",
      "avg / total       0.77      0.84      0.80       575\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(gs2.best_estimator_, 'GridSearched Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-28T15:28:31.467651",
     "start_time": "2016-10-28T15:28:31.323573"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagged GridSearched Logistic Regression accuracy score: 0.834782608696\n",
      "\n",
      "       acc  good  unacc  vgood\n",
      "acc     84     0     44      0\n",
      "good    23     0      0      0\n",
      "unacc    7     0    396      0\n",
      "vgood   21     0      0      0\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.66      0.64       128\n",
      "          1       0.00      0.00      0.00        23\n",
      "          2       0.90      0.98      0.94       403\n",
      "          3       0.00      0.00      0.00        21\n",
      "\n",
      "avg / total       0.77      0.83      0.80       575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(ensemble.BaggingClassifier(gs2.best_estimator_), 'Bagged GridSearched Logistic Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Decision Trees\n",
    "\n",
    "Let's see if Decision Trees perform better\n",
    "\n",
    "1. Initialize DT and test on Train/Test set\n",
    "- Find optimal params with Grid Search\n",
    "- See if Bagging improves the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-28T15:28:31.513184",
     "start_time": "2016-10-28T15:28:31.472027"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree accuracy score: 0.96\n",
      "\n",
      "       acc  good  unacc  vgood\n",
      "acc    113     3     12      0\n",
      "good     0    22      1      0\n",
      "unacc    6     0    397      0\n",
      "vgood    1     0      0     20\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.88      0.91       128\n",
      "          1       0.88      0.96      0.92        23\n",
      "          2       0.97      0.99      0.98       403\n",
      "          3       1.00      0.95      0.98        21\n",
      "\n",
      "avg / total       0.96      0.96      0.96       575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(tree.DecisionTreeClassifier(), \"Decision Tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-28T15:28:47.620387",
     "start_time": "2016-10-28T15:28:31.517021"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'min_samples_split': array([10, 20, 30, 40]), 'criterion': ['gini', 'entropy'], 'max_depth': [None, 5, 10, 20], 'min_samples_leaf': array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs3 = model_selection.GridSearchCV(tree.DecisionTreeClassifier(),\n",
    "                                   {'criterion': ['gini', 'entropy'],\n",
    "                                    'max_depth': [None, 5,10,20], \n",
    "                                    'min_samples_split': np.arange(10,50,10), \n",
    "                                    'min_samples_leaf': np.arange(5,20,1)},\n",
    "                                   cv=5)\n",
    "gs3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-28T15:28:47.644230",
     "start_time": "2016-10-28T15:28:47.624641"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearched Decision Trees accuracy score: 0.935652173913\n",
      "\n",
      "       acc  good  unacc  vgood\n",
      "acc    111     3     12      2\n",
      "good     5    17      1      0\n",
      "unacc    9     0    394      0\n",
      "vgood    0     5      0     16\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.87      0.88       128\n",
      "          1       0.68      0.74      0.71        23\n",
      "          2       0.97      0.98      0.97       403\n",
      "          3       0.89      0.76      0.82        21\n",
      "\n",
      "avg / total       0.94      0.94      0.94       575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(gs3.best_estimator_, 'GridSearched Decision Trees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-28T15:28:47.743823",
     "start_time": "2016-10-28T15:28:47.648361"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagged GridSearched Decision Trees accuracy score: 0.96347826087\n",
      "\n",
      "       acc  good  unacc  vgood\n",
      "acc    123     2      1      2\n",
      "good     0    20      0      3\n",
      "unacc   13     0    390      0\n",
      "vgood    0     0      0     21\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.96      0.93       128\n",
      "          1       0.91      0.87      0.89        23\n",
      "          2       1.00      0.97      0.98       403\n",
      "          3       0.81      1.00      0.89        21\n",
      "\n",
      "avg / total       0.97      0.96      0.96       575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(ensemble.BaggingClassifier(gs3.best_estimator_), 'Bagged GridSearched Decision Trees')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Support Vector Machines\n",
    "\n",
    "Let's see if SVM perform better\n",
    "\n",
    "1. Initialize SVM and test on Train/Test set\n",
    "- Find optimal params with Grid Search\n",
    "- See if Bagging improves the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-28T15:31:45.656175",
     "start_time": "2016-10-28T15:31:45.538262"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector accuracy score: 0.913043478261\n",
      "\n",
      "       acc  good  unacc  vgood\n",
      "acc    124     0      4      0\n",
      "good    17     5      0      1\n",
      "unacc   16     0    387      0\n",
      "vgood   12     0      0      9\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.97      0.84       128\n",
      "          1       1.00      0.22      0.36        23\n",
      "          2       0.99      0.96      0.97       403\n",
      "          3       0.90      0.43      0.58        21\n",
      "\n",
      "avg / total       0.93      0.91      0.90       575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(svm.SVC(), 'Support Vector')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Random Forest & Extra Trees\n",
    "\n",
    "Let's see if Random Forest and Extra Trees perform better\n",
    "\n",
    "1. Initialize RF and ET and test on Train/Test set\n",
    "- Find optimal params with Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model comparison\n",
    "\n",
    "Let's compare the scores of the various models.\n",
    "\n",
    "1. Do a bar chart of the scores of the best models. Who's the winner on the train/test split?\n",
    "- Re-test all the models using a 3 fold stratified shuffled cross validation\n",
    "- Do a bar chart with errorbars of the cross validation average scores. is the winner the same?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "We have encoded the data using a map that preserves the scale.\n",
    "Would our results have changed if we had encoded the categorical data using `pd.get_dummies` or `OneHotEncoder`  to encode them as binary variables instead?\n",
    "\n",
    "1. Repeat the analysis for this scenario. Is it better?\n",
    "- Experiment with other models or other parameters, can you beat your classmates best score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
