{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png)  Naive Bayes classifier\n",
    "Week 8 | 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LEARNING OBJECTIVES\n",
    "*After this lesson, you will be able to:*\n",
    "- Describe Naive Bayes\n",
    "- Choose a Naive Bayes implementation based on your use case\n",
    "- Implement a Naive Bayes model through scikit-learn\n",
    "\n",
    "### STUDENT PRE-WORK\n",
    "*Before this lesson, you should already be able to:*\n",
    "- Work with methods in scikit-learn\n",
    "- Conceptually explain the Bayesian posterior distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LESSON GUIDE\n",
    "| Timing | Type | Topic |\n",
    "| --- | --- | --- |\n",
    "| 5 min | [Opening](#opening) | Bayes' theorem and Naive Bayes |\n",
    "| 25 min | [Introduction](#introduction) | The basics of Naive Bayes |\n",
    "| 25 min | [Guided Practice](#Guided)  | Using the Naive Bayes Implementation in Scikit-learn |\n",
    "| 25 min | [Independent Practice](#Indy) | Apply your Naive Bayes on the data |\n",
    "| 5 min |  [Conclusion](#conclusion)| Concluding Remarks |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bayes' thereom, again:\n",
    "\n",
    "\n",
    "### $$P\\left(\\;A\\;|\\;B\\;\\right) = \\frac{P\\left(\\;B\\;|\\;A\\;\\right)P\\left(\\;A\\;\\right)}{P(\\;B\\;)}$$\n",
    "\n",
    "\n",
    "### $$P\\left(\\;model\\;|\\;data\\;\\right) = \\frac{P\\left(\\;data\\;|\\;model\\;\\right)P\\left(\\;model\\;\\right)}{P(\\;data\\;)} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Applying Bayes in supervised machine learning\n",
    "\n",
    "> Check: How would you apply this in a machine learning context?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can use this for classification problems.\\* Its canonical use case is spam classification (or text classification generally).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<sub><sup>\\*Or regression. But it doesn't work well.</sub></sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What would our formula look like?\n",
    "\n",
    "Let's say we're trying to predict 419 spam emails. M = 'million', S = 'is spam'.\n",
    "\n",
    "#### $$P\\left(\\;S\\;|\\;M\\;\\right) = \\frac{P\\left(\\;M\\;|\\;S\\;\\right)P\\left(\\;S\\;\\right)}{P(\\;M\\;)} = \\frac{P\\left(\\;M\\;|\\;S\\;\\right)P\\left(\\;S\\;\\right)}{P(\\;M\\;|\\;S)P(\\;S\\;) + P(\\;M\\;|\\;\\neg{S})P(\\;\\neg{S}\\;)}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can make some simplifying assumptions. Let's start by assuming an equal chance of spam / not spam. So:\n",
    "\n",
    "### $$ P\\left(\\;S\\;|\\;M\\;\\right) =\n",
    "\\frac{P\\left(\\;M\\;|\\;S\\;\\right)}\n",
    "{P(\\;M\\;|\\;S) + P(\\;M\\;|\\;\\neg{S})}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But we'll use more than one feature. Really, we want to see some feature vector $X_1, X_2, ..., X_n$:\n",
    "\n",
    "### $$P\\left(\\;S\\;|\\;X_1, X_2, ..., X_n\\;\\right) = \\frac{P\\left(\\;X_1, X_2, ..., X_n\\;|\\;S\\;\\right)}{P(\\;X_1, X_2, ..., X_n\\;|\\;S) + P(\\;X_1, X_2, ..., X_n\\;|\\;\\neg{S})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Since these features can take on different values in each observation, our calculation is really:\n",
    "\n",
    "### $$P\\left(\\;S\\;|\\;X_{1=x1}, X_{2=x2}, ..., X_{n=xn}\\;\\right) = \\frac{P\\left(\\;X_{1=x1}, X_{2=x2}, ..., X_{n=xn}\\;|\\;S\\;\\right)}{P(\\;X_{1=x1}, X_{2=x2}, ..., X_{n=xn}\\;|\\;S) + P(\\;X_{1=x1}, X_{2=x2}, ..., X_{n=xn}\\;|\\;\\neg{S})}$$\n",
    "\n",
    "\n",
    "With a lot of features, calculating their joint probabilities could get hairy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Simplify again, naively\n",
    "\n",
    "Joint probabilities are NBD if we *assume independence*: \n",
    "$P\\left(\\;X_{1=x1}, X_{2=x2}, ..., X_{n=xn}\\;|\\;S\\;\\right) = P\\left(\\;X_{1=x1} |\\;S\\;\\right) * P\\left(\\;X_{2=x2} |\\;S\\;\\right) ... P\\left(\\;X_{n=xn} |\\;S\\;\\right)$\n",
    "\n",
    "$$P\\left(\\;S\\;|\\;X_{1=x1}, X_{2=x2}, ..., X_{n=xn}\\;\\right) = \\prod_{i=1}^{n}P(X_i = x_i | \\;S\\;) / C$$\n",
    "\n",
    "Where C is some constant for our marginal probability of those data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### This gives a handy decision function (generalizable to k classes)\n",
    "\n",
    "![](./assets/images/nb_decision_rule.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using our Naive Bayes model\n",
    "\n",
    "How do we code this and instantiate models?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How would you?\n",
    "\n",
    "> Check: With a partner, jot down (pseudo)code for a Naive Bayes classifier. What are the inputs and outputs? How did you calculate probabilities? What implementation wrinkles do you notice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Moving toward a production implementation\n",
    "\n",
    "Possible issues to contend with:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- [Underflow](http://stackoverflow.com/questions/3704570/in-python-small-floats-tending-to-zero). Probabilites may very very small, too small for floating point arithmetic. We can solve by leveraging:\n",
    "\n",
    "$$log(ab) = log\\ a + log\\ b$$\n",
    "\n",
    "$$exp(log\\ x) = x$$\n",
    "\n",
    "So $P_1\\ *\\ P_2\\ ...\\ *\\ P_2 = exp(log\\ P_1 + ... + log\\ P_n)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- '0' probabilities. What if you never saw a feature value in your training data? We can use Laplace smoothing:\n",
    "\n",
    "$$\\hat\\theta_i= \\frac{x_i + \\alpha}{N + \\alpha d}  \\qquad (i=1,\\ldots,d)$$\n",
    "\n",
    "Where $\\alpha > 0$ is the smoothing parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Real-valued features. This brings us to *distributions*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The likelihood functions\n",
    "\n",
    "$P\\left(\\;X_{1=x1}, X_{2=x2}, ..., X_{n=xn}\\;|\\;S\\;\\right)$\n",
    "\n",
    "Bayesians tend to talk in terms of distributions of belief. Rather than point estimates of probabilities, we can use distributions.\n",
    "\n",
    "For a binary event, probability can be modeled with the **binomial distribution**.\n",
    "\n",
    "For > 2 discrete outcomes, the **multinomial distribution**.\n",
    "\n",
    "And if features are real-valued? **Gaussian**.\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Guided practice: Scikit-learn to the rescue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<a name = \"demo\"></a>\n",
    "### Using the Naive Bayes Implementation in Scikit-learn (15 mins)\n",
    "\n",
    "\n",
    "```python\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "\n",
    "# Import data into a numpy array\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "Y = np.array([1, 1, 1, 2, 2, 2])\n",
    "\n",
    "#Initialize a variable as the Guassian Naive Bayes classifier and fit it with the data\n",
    "clf = GaussianNB()\n",
    "clf.fit(X, Y)\n",
    "GaussianNB()\n",
    "\n",
    "# Predict a few instances\n",
    "print(clf.predict([[-0.8, -1]]))\n",
    "clf_pf = GaussianNB()\n",
    "clf_pf.partial_fit(X, Y, np.unique(Y))\n",
    "GaussianNB()\n",
    "print(clf_pf.predict([[-0.8, -1]]))\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T11:47:34.699515",
     "start_time": "2016-11-08T11:47:34.033984"
    },
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "\n",
    "# Import data into a numpy array\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "Y = np.array([1, 1, 1, 2, 2, 2])\n",
    "\n",
    "#Initialize a variable as the Guassian Naive Bayes classifier and fit it with the data\n",
    "clf = GaussianNB()\n",
    "clf.fit(X, Y)\n",
    "\n",
    "# Predict a few instances\n",
    "print clf.predict([[-0.8, -1]])\n",
    "clf_pf = GaussianNB()\n",
    "clf_pf.partial_fit(X, Y, np.unique(Y))\n",
    "print clf_pf.predict([[-0.8, -1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a name = \"Guided\"></a>\n",
    "## Independent practice: Naive-Bayes classifier with real data (25 mins)\n",
    "\n",
    "We're going to now try our hand at classifying some SPAM.\n",
    "\n",
    "```python\n",
    "# Work here\n",
    "from sklearn import naive_bayes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./assets/datasets/spam_base.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a name = \"Indy\"></a>\n",
    "## Apply your Naive Bayes on the data  (25 min)\n",
    "\n",
    "Now we should take the results above and try our hand with Naive Bayes. Which Naive Bayes classifier should we utilize? There are 3 variants (Normal, Bernoulli, Multinomial). Could we do some conversion of the data and try one or the other? How should we think about diagnosing the model performance?\n",
    "\n",
    "Again, we must defer to the docs:\n",
    "\n",
    "- [Docs 1](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)\n",
    "- [Docs 2](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html)\n",
    "- [Docs 3](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html)\n",
    "\n",
    "The differences can be summarized as follows\n",
    "-    ***BernoulliNB*** is designed for binary/boolean features\n",
    "-    The ***multinomial Naive Bayes classifier*** is suitable for classification with discrete features (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as `tf-idf` may also work\n",
    "-    ***GaussianNB*** is designed for continuous features (that can be scaled between 0,1) and is assumed to be normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T11:52:15.130627",
     "start_time": "2016-11-08T11:52:14.711471"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T11:56:24.115753",
     "start_time": "2016-11-08T11:56:24.000301"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>...</th>\n",
       "      <th>X48</th>\n",
       "      <th>X49</th>\n",
       "      <th>X50</th>\n",
       "      <th>X51</th>\n",
       "      <th>X52</th>\n",
       "      <th>X53</th>\n",
       "      <th>X54</th>\n",
       "      <th>X55</th>\n",
       "      <th>X56</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     X0    X1    X2   X3    X4    X5    X6    X7    X8    X9 ...   X48    X49  \\\n",
       "0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00 ...  0.00  0.000   \n",
       "1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94 ...  0.00  0.132   \n",
       "2  0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25 ...  0.01  0.143   \n",
       "3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63 ...  0.00  0.137   \n",
       "4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63 ...  0.00  0.135   \n",
       "\n",
       "   X50    X51    X52    X53    X54  X55   X56  Y  \n",
       "0  0.0  0.778  0.000  0.000  3.756   61   278  1  \n",
       "1  0.0  0.372  0.180  0.048  5.114  101  1028  1  \n",
       "2  0.0  0.276  0.184  0.010  9.821  485  2259  1  \n",
       "3  0.0  0.137  0.000  0.000  3.537   40   191  1  \n",
       "4  0.0  0.135  0.000  0.000  3.537   40   191  1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./assets/datasets/spam_base.csv\", header=None)\n",
    "data.columns = [\"X\"+str(i) for i in data.columns[:-1]] + [\"Y\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T12:02:48.051179",
     "start_time": "2016-11-08T12:02:48.043242"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We need to separate the features from the target.\n",
    "X = data[[i for i in data.columns if \"X\" in i]]\n",
    "y = data[\"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T12:06:39.740258",
     "start_time": "2016-11-08T12:06:39.735956"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_features = list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T12:08:30.382042",
     "start_time": "2016-11-08T12:08:30.357511"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define several different feature sets. Do we get more or better accuracy? Is more always better?\n",
    "X10 = X[np.random.choice(all_features, size=10, replace=False)]\n",
    "X20 = X[np.random.choice(all_features, size=20, replace=False)]\n",
    "X30 = X[np.random.choice(all_features, size=30, replace=False)]\n",
    "X40 = X[np.random.choice(all_features, size=40, replace=False)]\n",
    "X50 = X[np.random.choice(all_features, size=50, replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T12:10:26.509182",
     "start_time": "2016-11-08T12:10:26.504470"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Discuss... and think about what kind of diagnosis metrics we could utilize for the mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T12:12:26.899479",
     "start_time": "2016-11-08T12:12:26.886658"
    },
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5909584872853727"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf10 = naive_bayes.GaussianNB()\n",
    "clf10.fit(X10,y)\n",
    "score10 = clf10.score(X10,y)\n",
    "score10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T12:12:56.312643",
     "start_time": "2016-11-08T12:12:56.293186"
    },
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64073027602695065"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf20 = naive_bayes.GaussianNB()\n",
    "clf20.fit(X20,y)\n",
    "score20 = clf20.score(X20,y)\n",
    "score20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T12:12:56.312643",
     "start_time": "2016-11-08T12:12:56.293186"
    },
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68919800043468815"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf30 = naive_bayes.GaussianNB()\n",
    "clf30.fit(X30,y)\n",
    "score30 = clf30.score(X30,y)\n",
    "score30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T12:12:56.312643",
     "start_time": "2016-11-08T12:12:56.293186"
    },
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74005650945446644"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf40 = naive_bayes.GaussianNB()\n",
    "clf40.fit(X40,y)\n",
    "score40 = clf40.score(X40,y)\n",
    "score40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T12:12:56.312643",
     "start_time": "2016-11-08T12:12:56.293186"
    },
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81351880026081291"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf50 = naive_bayes.GaussianNB()\n",
    "clf50.fit(X50,y)\n",
    "score50 = clf50.score(X50,y)\n",
    "score50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T12:13:03.430654",
     "start_time": "2016-11-08T12:13:03.408379"
    },
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82286459465333628"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfall = naive_bayes.GaussianNB()\n",
    "clfall.fit(X,y)\n",
    "scoreall = clfall.score(X,y)\n",
    "scoreall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T12:30:28.150053",
     "start_time": "2016-11-08T12:30:28.137655"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfall.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T12:13:47.365249",
     "start_time": "2016-11-08T12:13:47.137431"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-08T12:14:03.821838",
     "start_time": "2016-11-08T12:14:03.462909"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhIAAAFkCAYAAAB1rtL+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVDSDhCRJKtr/ByzGQtEWG5E2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11730f310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([10,20,30,40,50,57],[score10, score20, score30, score40, score50, scoreall], '-', marker=\"o\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a name = \"conclusion\"></a>\n",
    "## Conclusion (5 min)\n",
    "\n",
    "\n",
    "How does Naive Bayes fit into your toolkit? What are the pros and cons? How do you choose between variants?\n",
    "\n",
    "#### Additional Resources\n",
    "\n",
    "- [An interesting slide from a Stanford MOOC which had a section on Naive Bayes](https://web.stanford.edu/class/cs124/lec/naivebayes.pdf)\n",
    "- [A much more technical paper comparing Naive Bayes to Logistics Regressions](https://www.cs.cmu.edu/~tom/mlbook/NBayesLogReg.pdf)\n",
    "- [More exposition on Naive Bayes](http://blog.yhat.com/posts/naive-bayes-in-python.html)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
